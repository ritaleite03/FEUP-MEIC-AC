{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "The metrics that will be used to evaluate this stage are:\n",
    "\n",
    "- **Integration**, this is, converting different data value formats AND entity matching between different sources;\n",
    "\n",
    "- **Quality**, assessment of dimensions;\n",
    "\n",
    "- **Cleaning**, systematic redundancy removal of redundant attributes, missing data, replace MVs with complex methods (e.g. regression, classification) with correct experimental setup, identify and discuss outliers and address them with complex approaches (technical or domain-dependent);\n",
    "\n",
    "- **Transformation** for algorithm compatibility, adequate complex discretization or rescaling;\n",
    "\n",
    "- **Feature Engineering and Selection** from tabular data, complex methods (e.g. aggregation) and knowledge (e.g. business concepts), and correct and combined use of filter and wrapper based methods;\n",
    "\n",
    "- **Sampling** for domain-specific purposes, focus on the appropriate subset of the population, and for development, start with a very small sample and scale up to a significant sample;\n",
    "\n",
    "- **Unbalanced** - you used advanced methods (e.g. SMOTE) correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Load data and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "awards_players = pd.read_csv(\"data/awards_players.csv\")\n",
    "coaches = pd.read_csv(\"data/coaches.csv\")\n",
    "players_teams = pd.read_csv(\"data/players_teams.csv\")\n",
    "players = pd.read_csv(\"data/players.csv\")\n",
    "series_post = pd.read_csv(\"data/series_post.csv\")\n",
    "teams_post = pd.read_csv(\"data/teams_post.csv\")\n",
    "teams = pd.read_csv(\"data/teams.csv\")\n",
    "\n",
    "tables = {\n",
    "    \"Awards Players\": awards_players,\n",
    "    \"Coaches\": coaches,\n",
    "    \"Players Teams\": players_teams,\n",
    "    \"Players\": players,\n",
    "    \"Series Post\": series_post,\n",
    "    \"Teams Post\": teams_post,\n",
    "    \"Teams\": teams\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns where all the entries have the same value\n",
    "def clean_remove_columns_equal(name):\n",
    "    \n",
    "    before = len(tables[name].columns)\n",
    "    nunique = tables[name].nunique()\n",
    "    cols_to_drop = nunique[nunique == 1].index\n",
    "    tables[name] = tables[name].drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    if( before != len( tables[name].columns)):\n",
    "        print( f\"(Only one value) {name} went from {before} to {len(tables[name].columns)} columns : {cols_to_drop.to_list()}\")\n",
    "\n",
    "# remove columns where all the entries have null values\n",
    "def clean_remove_columns_na(name):\n",
    "    \n",
    "    before_cols = tables[name].columns\n",
    "    tables[name] = tables[name].dropna(axis=1, how='all')\n",
    "    after_cols = tables[name].columns\n",
    "    \n",
    "    if(len(before_cols) != len(after_cols)):\n",
    "        print(f\"(Only missing data) {name} went from {len(before_cols)} to {len(after_cols)} columns : {list(filter(lambda x: x not in after_cols, before_cols))}\")\n",
    "\n",
    "# identify columns that have null values\n",
    "def clean_identify_columns_na(name):\n",
    "    \n",
    "    cols_with_empty_values = tables[name].columns[tables[name].isnull().any() ].to_list()\n",
    "    size = len(cols_with_empty_values)\n",
    "    \n",
    "    if size > 0:\n",
    "        print(f\"{name} has {size} columns with missing data : {cols_with_empty_values}\")\n",
    "        \n",
    "# identify pairs of very correlated features\n",
    "def clean_identify_correlated_features(name):    \n",
    "    features = []\n",
    "    data_converted = tables[name].copy()\n",
    "    \n",
    "    for col in data_converted.select_dtypes(include=['object']).columns:\n",
    "        data_converted[col], _ = pd.factorize(data_converted[col])\n",
    "\n",
    "    matrix = data_converted.corr()\n",
    "    for i in range(len(matrix.columns)):\n",
    "        for j in range(i):\n",
    "            value = matrix.iloc[i,j]\n",
    "            if abs(value) > 0.95:\n",
    "                name_i = matrix.columns[i]\n",
    "                name_j = matrix.columns[j]\n",
    "                features.append((name_i,name_j,value))\n",
    "\n",
    "    return features\n",
    "\n",
    "# write contents to file\n",
    "def table_to_csv(name):\n",
    "    os.makedirs('data_prepared', exist_ok=True)\n",
    "    path = os.path.join('data_prepared', name.lower().replace(' ', '_') + \".csv\")\n",
    "    tables[name].to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Clean all the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by removing columns that have the same value in every entry and columns that have all entries empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Only one value) Awards Players went from 4 to 3 columns : ['lgID']\n",
      "(Only one value) Coaches went from 9 to 8 columns : ['lgID']\n",
      "(Only one value) Players Teams went from 43 to 42 columns : ['lgID']\n",
      "(Only one value) Players went from 10 to 8 columns : ['firstseason', 'lastseason']\n",
      "(Only one value) Series Post went from 9 to 7 columns : ['lgIDWinner', 'lgIDLoser']\n",
      "(Only one value) Teams Post went from 5 to 4 columns : ['lgID']\n",
      "(Only one value) Teams went from 61 to 53 columns : ['lgID', 'seeded', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB']\n",
      "(Only missing data) Teams went from 53 to 52 columns : ['divID']\n"
     ]
    }
   ],
   "source": [
    "# clean datasets\n",
    "for table in tables.keys():\n",
    "    clean_remove_columns_equal(table)\n",
    "    clean_remove_columns_na(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then removed columns that do not contain relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables['Players'] = tables['Players'].drop(['college', 'collegeOther', 'birthDate', 'deathDate'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to change the `tmID` column of all the datasets as it may not correspond to the `franchID` column of the teams dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapTeam = {}\n",
    "for index, row in teams[['tmID', 'franchID']].iterrows():\n",
    "    mapTeam [row['tmID']] = row['franchID']\n",
    "\n",
    "tables['Teams']['tmID'] = tables['Teams']['tmID'].replace(mapTeam) \n",
    "tables['Coaches']['tmID'] = tables['Coaches']['tmID'].replace(mapTeam) \n",
    "tables['Players Teams']['tmID'] = tables['Players Teams']['tmID'].replace(mapTeam) \n",
    "tables['Series Post']['tmIDWinner'] = tables['Series Post']['tmIDWinner'].replace(mapTeam) \n",
    "tables['Series Post']['tmIDLoser'] = tables['Series Post']['tmIDLoser'].replace(mapTeam) \n",
    "tables['Teams Post']['tmID'] = tables['Teams Post']['tmID'].replace(mapTeam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare teams.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several attributes that are highly correlated with each other and may not be necessary in the Teams dataset. So let's make some changes:\n",
    "\n",
    "- As we had already noticed previously, `tmID` and `franchID` are always the same, except in some specific cases. They are not equal only when the name under which the team participated in the competition (`tmID`) is not the same as its current name (`franchID`), that is, it changed its name.\n",
    "\n",
    "- The `name` and `arena` attributes, which give us the full name of the team and the name of its arena, are not necessary, as `tmID` is sufficient as an identifier.\n",
    "\n",
    "- Regarding the attributes referring to performance in the season, knowing that the `GP` attribute varies between two values, 32 and 34, depending on the year. In both cases the number of games is even, with half of them played at home and the rest away. Therefore:\n",
    "\n",
    "    - The `GP` attribute can be obtained by doing `won + lost`.\n",
    "    \n",
    "    - The `homeL` attribute can be obtained by doing `GP/2 - homeW`.\n",
    "    \n",
    "    - The `awayL` attribute can be obtained by doing `lost - homeL`.\n",
    "    \n",
    "    - The `awayW` attribute can be obtained by doing `won - homeW`.\n",
    "\n",
    "- In relation to the attributes referring to offensive statistics, the same ideas can be replicated for defensive statistics.\n",
    "\n",
    "    - The attribute `o_reb` can be obtained `o_oreb + o_dreb`\n",
    "\n",
    "    - The attribute `d_reb` can be obtained `d_oreb + d_dreb`.\n",
    "\n",
    "    - The attribute `o_pts` can be obtained `2 * ( o_fgm + o_3pm ) + 3 * o_3pm + o_ftm`.\n",
    "\n",
    "    - The attribute `d_pts` can be obtained `2 * ( d_fgm + d_3pm ) + 3 * d_3pm + d_ftm`.\n",
    "\n",
    "- In relation to the attributes relating to team rebounding, the same ideas can be replicated for the opposing team's team rebounding.\n",
    "\n",
    "    - The `tmTRB` attribute can be obtained `tmORB + tmDRB`.\n",
    "\n",
    "    - The `opptmTRB` attribute can be obtained `opptmORB + opptmDRB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Teams had 52 columns\n",
      "After Teams has 41 columns\n"
     ]
    }
   ],
   "source": [
    "# eliminate redundant attributes\n",
    "\n",
    "print(f\"Before Teams had {len(tables['Teams'].columns)} columns\")\n",
    "tables['Teams'] = tables['Teams'].drop(['franchID','name','arena'], axis=1)\n",
    "tables['Teams'] = tables['Teams'].drop(['GP','homeL','awayL','awayW'], axis=1)\n",
    "tables['Teams'] = tables['Teams'].drop(['o_reb','d_reb','o_pts','d_pts'], axis=1)\n",
    "print(f\"After Teams has {len(tables['Teams'].columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by looking at how many awards each player and coach received in a given year, and we add an `awards` column with that information to the `Coaches` and `Players Teams` datasets.\n",
    "\n",
    "With that information, we can group it by teams, and add two new columns to the `Teams` table, `awards_coaches` and `awards_players`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join awards.csv in teams.csv\n",
    "\n",
    "player_awards_count = tables['Awards Players'].groupby(['playerID', 'year']).size().reset_index(name='awards')\n",
    "tables['Players Teams'] = tables['Players Teams'].merge(player_awards_count, on=['playerID', 'year'], how='left')\n",
    "tables['Players Teams']['awards'] = tables['Players Teams']['awards'].fillna(0).astype(int)\n",
    "\n",
    "coach_awards = tables['Awards Players'].rename(columns={'playerID': 'coachID'})\n",
    "coach_awards_count = coach_awards.groupby(['coachID', 'year']).size().reset_index(name='awards')\n",
    "tables['Coaches'] = tables['Coaches'] .merge(coach_awards_count, on=['coachID', 'year'], how='left')\n",
    "tables['Coaches'] ['awards'] = tables['Coaches'] ['awards'].fillna(0).astype(int)\n",
    "\n",
    "team_players_count = tables['Players Teams'].groupby(['tmID', 'year'])['awards'].sum().reset_index()\n",
    "team_players_count = team_players_count.rename(columns={'awards': 'awards_players'})\n",
    "tables['Teams'] = tables['Teams'].merge(team_players_count, on=[ 'year','tmID'], how='left')\n",
    "tables['Teams']['awards_players'] = tables['Teams']['awards_players'].fillna(0).astype(int)\n",
    "\n",
    "team_coaches_count = tables['Coaches'].groupby(['tmID', 'year'])['awards'].sum().reset_index()\n",
    "team_coaches_count = team_coaches_count.rename(columns={'awards': 'awards_coaches'})\n",
    "tables['Teams'] = tables['Teams'].merge(team_coaches_count, on=['tmID', 'year'], how='left')\n",
    "tables['Teams']['awards_coaches'] = tables['Teams']['awards_coaches'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join of teams_post.csv in teams.csv\n",
    "\n",
    "tables['Teams'].columns = ['teams_' + col for col in tables['Teams'].columns]\n",
    "tables['Teams Post'].columns = ['teams_post_' + col for col in tables['Teams Post'].columns]\n",
    "tables['Coaches'].columns = ['coaches_' + col for col in tables['Coaches'].columns]\n",
    "\n",
    "tables['Teams'] = pd.merge( tables['Teams'], tables['Teams Post'], left_on=['teams_tmID', 'teams_year'], right_on=['teams_post_tmID', 'teams_post_year'], how='left')\n",
    "tables['Teams'] = tables['Teams'].drop( ['teams_post_year', 'teams_post_tmID', 'coaches_year'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare players_teams.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In relation to the attributes referring to statistics of the games played, there are some attributes that are not necessary:\n",
    "\n",
    "    - The attribute `rebounds` can be obtained `oRebounds + dRebounds`\n",
    "\n",
    "    - The attribute `PostRebounds` can be obtained `PostoRebounds + PostdRebounds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Players Teams had 43 columns\n",
      "After Players Teams has 41 columns\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before Players Teams had {len(tables['Players Teams'].columns)} columns\")\n",
    "tables['Players Teams'] = tables['Players Teams'].drop(['rebounds', 'PostRebounds'], axis=1)\n",
    "print(f\"After Players Teams has {len(tables['Players Teams'].columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join of players.csv in players_teams.csv\n",
    "\n",
    "tables['Players Teams'].columns = ['players_teams_' + col for col in tables['Players Teams'].columns]\n",
    "tables['Players'].columns = ['players_' + col for col in tables['Players'].columns]\n",
    "\n",
    "tables['Players Teams'] = pd.merge( tables['Players Teams'], tables['Players'], left_on='players_teams_playerID', right_on='players_bioID', how='left')\n",
    "tables['Players Teams'] = tables['Players Teams'].drop( ['players_bioID'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join of teams.csv in players_teams.csv\n",
    "\n",
    "tables['Players Teams'] = pd.merge( tables['Players Teams'], tables['Teams'], left_on=['players_teams_year','players_teams_tmID'], right_on=['teams_year','teams_tmID'], how='left')\n",
    "tables['Players Teams'] = tables['Players Teams'].drop( ['teams_year','teams_tmID'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Save prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in tables.keys():\n",
    "    table_to_csv(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
