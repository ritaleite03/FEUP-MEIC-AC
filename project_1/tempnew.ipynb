{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "# Configuração da semente para garantir resultados reprodutíveis\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Definir a semente também no Optuna e no SVM\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)  # Para evitar logs excessivos do Optuna\n",
    "\n",
    "# Leitura dos dados\n",
    "teams = pd.read_csv(\"data_prepared/teams.csv\")\n",
    "temp_teams = teams[teams['confID'] == \"EA\"]\n",
    "label_encoder = LabelEncoder()\n",
    "numerical_features = teams.select_dtypes(include=['float', 'int']).columns\n",
    "numerical_features = numerical_features.drop('year')\n",
    "scaler = StandardScaler()\n",
    "teams[numerical_features] = scaler.fit_transform(teams[numerical_features])\n",
    "teams['playoff'] = teams['playoff'].map({'Y': 1, 'N': 0})\n",
    "teams['confID'] = teams['confID'].map({'EA': 0, 'WE': 1})\n",
    "\n",
    "def encode_categorical_columns(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if col == 'playoff' or col == 'confID': continue\n",
    "        else: df[col] = label_encoder.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "encode_categorical_columns(teams)\n",
    "teams = teams.fillna(0)\n",
    "\n",
    "# Normalize predictions\n",
    "def normalize_predictions(predictions):\n",
    "    return (predictions - np.min(predictions)) / (np.max(predictions) - np.min(predictions))\n",
    "\n",
    "# Calculate error\n",
    "def get_error(pred_proba, label_playoff):\n",
    "    return sum(abs(pred - label) for pred, label in zip(pred_proba, label_playoff))\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def get_train_and_test_data(data, year):\n",
    "    train = data[((data['year'] < year) | (data['year'] > year)) & (data['year'] != 11)].drop(\"year\", axis=1)\n",
    "    test = data[data['year'] == year].drop(\"year\", axis=1)\n",
    "    X_train, Y_train = train.drop(\"playoff\", axis=1), train[\"playoff\"]\n",
    "    X_test, Y_test = test.drop(\"playoff\", axis=1), test[\"playoff\"]\n",
    "\n",
    "    smote = SMOTE(random_state=SEED)\n",
    "    X_train, Y_train = smote.fit_resample(X_train, Y_train)\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "# Select best features using RFECV\n",
    "def select_best_features(X_train, Y_train, feature_list, n_features):\n",
    "    svc = SVC(kernel=\"linear\", random_state=SEED)\n",
    "    selector = RFECV(estimator=svc, step=1, min_features_to_select=n_features, cv=3, scoring='accuracy')\n",
    "    selector.fit(X_train[feature_list], Y_train)\n",
    "    selected_features = [feature_list[i] for i in range(len(feature_list)) if selector.support_[i]]\n",
    "    return selected_features + ['tmID']\n",
    "\n",
    "# Run model pipeline\n",
    "def run_model(model, data, year, number, only_df=False, feature_list=None, n_features=10):\n",
    "    feature_list = feature_list or [\n",
    "        'o_fgm', 'o_fga', 'o_ftm', 'o_fta', 'o_3pm', 'o_3pa', 'o_oreb', 'o_dreb', 'o_asts',\n",
    "        'o_pf', 'o_stl', 'o_to', 'o_blk', 'o_pts', 'd_fgm', 'd_fga', 'd_ftm', 'd_fta', 'd_3pm',\n",
    "        'd_3pa', 'd_oreb', 'd_dreb', 'd_asts', 'd_pf', 'd_stl', 'd_to', 'd_blk', 'd_pts', 'won',\n",
    "        'lost', 'homeW', 'homeL', 'awayW', 'awayL', 'confW', 'confL', 'min', 'wonPost', 'lostPost',\n",
    "        'wonPointsPost', 'lostPointsPost', 'awards_players', 'awards_coaches', 'offensive_efficiency',\n",
    "        'defensive_efficiency', 'play_percent', 'factors4', 'possession', 'opponent_possession',\n",
    "        'avg_pie', 'avg_per'\n",
    "    ]\n",
    "    X_train, Y_train, X_test, Y_test = get_train_and_test_data(data, year)\n",
    "    selected_features = select_best_features(X_train, Y_train, feature_list, n_features)\n",
    "    X_train, X_test = X_train[selected_features], X_test[selected_features]\n",
    "    \n",
    "    start_timer = time.time()\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    error = get_error(y_pred_proba, Y_test)\n",
    "    \n",
    "    y_pred = np.zeros_like(y_pred_proba)\n",
    "    y_pred[np.argsort(y_pred_proba)[-number:]] = 1\n",
    "    stop_timer = time.time()\n",
    "\n",
    "    prediction_df = pd.DataFrame({'tmID': X_test['tmID'], 'Playoff': y_pred_proba})\n",
    "    prediction_df['tmID'] = label_encoder.inverse_transform(X_test['tmID'])\n",
    "\n",
    "    if only_df: return prediction_df\n",
    "    prediction_df['Playoff_Binary'] = y_pred\n",
    "    prediction_df['Playoff_Labeled'] = Y_test.values\n",
    "    \n",
    "    time_elapsed = stop_timer - start_timer\n",
    "    metrics = calculate_metrics(Y_test, y_pred, y_pred_proba)\n",
    "    metrics.update({\"time\": time_elapsed, \"error\": error})\n",
    "    return prediction_df, metrics\n",
    "\n",
    "# Metrics calculation\n",
    "def calculate_metrics(y_true, y_pred, y_proba):\n",
    "    return {\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"auc\": roc_auc_score(y_true, y_proba)\n",
    "    }\n",
    "\n",
    "# Run model by conferences\n",
    "def run_model_by_conferences(model, year, data):\n",
    "    if year == 11:\n",
    "        east_pred_df = run_model(model, data[data['confID'] == 0], year, 4, True)\n",
    "        west_pred_df = run_model(model, data[data['confID'] == 1], year, 4, True)\n",
    "        pred_df = pd.concat([east_pred_df, west_pred_df])\n",
    "        pred_df['tmID'] = pred_df['tmID'].replace(\"DET\", \"TUL\") # replace team that has different 'tmID' and 'franchID\n",
    "        pred_df = pred_df.sort_values('tmID')\n",
    "        prob = pred_df['Playoff']\n",
    "        pred_df['Playoff'] = prob * (8 / prob.sum())\n",
    "        pred_df['Playoff'] = pred_df['Playoff'].round(2)\n",
    "        print(pred_df['Playoff'].sum())\n",
    "        return pred_df\n",
    "\n",
    "    stats = {}\n",
    "    for confID in [0, 1]:\n",
    "        conf_data = data[data['confID'] == confID]\n",
    "        _, conf_stats = run_model(model, conf_data, year, 4)\n",
    "        stats[confID] = conf_stats\n",
    "\n",
    "    combined_stats = {k: np.mean([v[k] for v in stats.values()]) for k in stats[0]}\n",
    "    print(f\"Metrics: {combined_stats}\")\n",
    "    return combined_stats\n",
    "\n",
    "# Hyperparameter tuning\n",
    "def svm_objective(trial):\n",
    "    C = trial.suggest_loguniform('C', 1e-5, 1e2)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_loguniform('gamma', 1e-5, 1e1) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    coef0 = trial.suggest_float('coef0', -1, 1) if kernel in ['poly', 'sigmoid'] else 0\n",
    "    class_weight = trial.suggest_categorical('class_weight', [None, 'balanced'])\n",
    "\n",
    "    scores = []\n",
    "    for i in range(2,11):\n",
    "        X_train, Y_train, _, _ = get_train_and_test_data(teams, i)\n",
    "        model = SVC(C=C, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0, class_weight=class_weight, random_state=SEED)\n",
    "        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "        score = cross_val_score(model, X_train, Y_train, cv=cv, scoring='accuracy').mean()\n",
    "        scores.append(score)\n",
    "    \n",
    "    return 1 - np.mean(scores)\n",
    "\n",
    "# Main Execution\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "study.optimize(svm_objective, n_trials=50)\n",
    "best_params = study.best_params\n",
    "\n",
    "final_model = SVC(**best_params, random_state=SEED, probability=True)\n",
    "run_model_by_conferences(final_model, 11, teams)\n",
    "\n",
    "BEST_MODELS = {\"svm\": run_model_by_conferences(final_model, 11, teams)}\n",
    "os.makedirs('data_prediction', exist_ok=True)\n",
    "for k,v in BEST_MODELS.items():\n",
    "    v.to_csv(os.path.join('data_prediction', k+'.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
